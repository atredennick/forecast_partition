---
title: A simulation-based approach for quantifying and partitioning uncertainty to improve ecological forecasts
author: Andrew T. Tredennick$^{1}$, Peter B. Adler$^1$, and others$^{2}$
csl: ecology.csl
output:
  pdf_document:
    keep_tex: yes
  html_document: default
geometry: left=1in, right=1in, top=1in, bottom=1in, headheight=12pt, letterpaper
header-includes:
- \usepackage{mathptmx}
- \usepackage{upgreek}
- \usepackage{bm}
- \usepackage{setspace}
- \usepackage{booktabs}
- \doublespacing
- \usepackage{lineno}
- \linenumbers
fontsize: 12pt
bibliography: /Users/atredenn/Dropbox/Bibliography/ecocast.bib
---
<!-- bibliography: lemonade_ms.bib -->
\setlength{\abovedisplayskip}{0pt}
\raggedright

$^1$ Department of Wildland Resources and the Ecology Center, Utah State University, Logan, UT, United States

$^2$ Department of somewhere

# Abstract

Making informed ecosystem management decisions in the face of rapid environmental change requires forecasts from models of ecological processes.
However, forecasts from ecological models are often associated with high degrees of uncertainty, making it difficult for such forecasts to inform decision-making processes.
To make progress toward the goal of reliable and informative ecological forecasts, we need to know from where forecast uncertainty arises.
Such knowledge can guide investment in future research that will most improve forecast skill.
There is a rich history of analytical expressions that partition the variance of future dynamics, but these expressions suffer from necessary assumptions such as linear dynamics and small-variance approximations that exclude interactions.
Similarly, the earth systems modeling community has developed methods for paritioning uncertainty of model projections, but these operate at a different modeling grain than most of ecology.
Building on these approaches, we develop a simulation-based approach for quantifying and partitioning forecast uncertainty from Bayesian state-space models that overcomes the limitations of previous analytical approaches.
Our approach is similar to an Analysis of Variance, where the total variance of a forecast is paritioned among its constituent parts, namely initial conditions uncertainty, parameter uncertainty, driver uncertainty, process error, and their interactions.
We demonstrate the approach with simulated data and with an empirical example using data from the Yellowstone bison population.
We also provide functions written in the statistical programming language R, which will allow others using Bayesian state-space models to employ our approach in their own research.

*Keywords: Bayesian state-space model, forecast, Markov chain Monte Carlo, prediction, population model, uncertainty, Yellowstone bison*

# Introduction

A fundamental challenge facing society is to predict the ecological impacts of global environmental changes such as nitrogen deposition, climate change, and habitat fragmentation.
Each of these global change drivers have now exceeded their historical ranges of variability [@Steffen2015], ushering in a no-analog era in which the past cannot predict the future.
We can, however, look to the past to parameterize models that allow us to forecast the future states of ecological systems [@Clark2001; @Dietze2018].
Ecologists are in an excellent position to meet this forecasting challenge because we have spent decades gaining understanding of the processes that regulate populations, communities, and ecosystems.
However, we lack a systematic understanding of the current limits to ecological forecasts.
As a result, we do not know how to allocate research effort to improve our forecasts.

Making poor forecasts is inevitable as ecology matures into a more predictive science.
The key is to learn from our failures so that forecasts become more accurate over time.
The success of meteorological forecasting tells us that basic research on the causes of forecast uncertainty is an essential component of this learning process [@Bauer2015].

Various approaches have been used to characterize and partition forecast uncertainty [@Sobol1993; @Cariboni2007].
For example, consider a dynamic model designed to predict some state *y* in the future ($y_{t+1}$) based on the current state ($y_{t}$), an environmental driver(s) ($x$), parameters ($\theta$), and process error ($\epsilon$).
We can then write a general form of the model as:

\begin{align}
y_{t+1} = f(y_t, x_t|\theta) + \epsilon_{t+1},
\end{align}

which states that $y$ at time $t+1$ is a function of $y$ and $x$ at time $t$ conditional on the model parameters ($\theta$) plus process error ($\epsilon$).
Ignoring covariance among factors and assuming linear dynamics, @Dietze2017a, following @Sobol1993 and @Cariboni2007, suggests that forecast variance ($Var[y_{t+1}]$) is approximately:

\begin{align}
Var[y_{t+1}] \approx \underbrace{\left(\frac{\delta f}{\delta y} \right)^2}_{\text{stability}} 
               \underbrace{\vphantom{ \left(\frac{\delta f}{\delta y} \right)^2 } Var[y_t]}_{\text{IC uncert.}} +
               \underbrace{\vphantom{ \left(\frac{\delta f}{\delta y} \right)^2 }\left(\frac{\delta f}{\delta x} \right)^2}_{\text{driver sens.}} 
               \underbrace{\vphantom{ \left(\frac{\delta f}{\delta y} \right)^2 } Var[x_t]}_{\text{driver uncert.}} +
               \underbrace{\vphantom{ \left(\frac{\delta f}{\delta y} \right)^2 }\left(\frac{\delta f}{\delta \theta} \right)^2}_{\text{param sens.}}
               \underbrace{\vphantom{ \left(\frac{\delta f}{\delta y} \right)^2 } Var[\theta]}_{\text{param. uncert.}} +
               \underbrace{\vphantom{ \left(\frac{\delta f}{\delta y} \right)^2 } Var[\epsilon_{t+1}]}_{\text{process error}},
\end{align}

where each additive term follows a pattern of *sensitivity* times *variance* and "IC uncert." refers to "*I*nitial *C*onditions uncertainty."
The variance attributable to any particular factor is a function of how sensitive the model is to the factor and the variance of that factor.
For example, the atmosphere is a chaotic system, meaning its dynamics are internally unstable and sensitive to initial conditions uncertainty.
This is why billions of dollars are spent each year to measure meterological variables -- meterologists learned that the key to reducing forecast error $(Var[y_{t+1}])$ was to reduce the uncertainty of initial conditions ($Var[y_t]$).
In contrast, ecologists are attempting to make actionable forecasts with little knowledge of which term in Eq. 2 dominates forecast error.
Knowing which term dominates forecast error in different ecological settings will advance our fundamental understanding of the natural world and immediately impact practical efforts to monitor, model, and predict ecological dynamics.

While having an analytical expression such as Eq. 2 is satisfying, arriving at the expression involves strict assumptions.
First, Eq. 2 only holds when the underlying dynamics are linear, which may not be the case for many populations and models.
Second, Eq. 2 only includes additive effects of each factor because the Taylor series decomposition requires small-variance approximations that eliminate interactions.
But, interactions among the factors are probably commone.
For example, in a simple simulation of an AR(1) process, we show that initial conditions uncertainty and parameter error interact to generate the full spread of forecast variance (Figure 1).
Therefore, progress in quantifying and partioning forecast uncertainty requires a more flexible approach than that provided by Eq. 2.

<!-- Rarely will only a single term in Eq. 2 determine forecast variance, and the importance of each term might shift over time [@Dietze2017a]. -->
<!-- For example, efforts to describe uncertainty in models of the global carbon cycle show that forecast variance from differences among carbon-emissions scenarios starts small but rises over time [@Lovenduski2017]. -->
<!-- Contrary to the analytical expression in Eq. 2, terms might also interact, rather than having additive effects. -->
<!-- A simple simulation experiment shows this clearly: initial conditions uncertainty and parameter uncertainty interact to produce the full spread of forecast error from an AR1 process model (Figure 1). -->
<!-- Simply relying on Eq. 2 could lead to a mischaracterization of the forces driving forecast uncertainty. -->
<!-- Therefore, progress requires a practical approach that can partition the main effects and interactions of each term in Eq. 2. -->

![ Example of forecast uncertainty with different sources of error set to zero. Each line represents one realization, out of 200, from an order-one autoregressive model (AR1 process). Contrary to the analytical expression (Eq. 2), initial conditions uncertainty and parameter uncertainty clearly interact. The spread of lines in (A) is not wholly because of initial conditions uncertainty (B) or parameter uncertainty (C), it is their combined influence that causes the spread of realizations in (A). At least in this example, process error (D) does appear to be independent, but we used a small value of process error to highlight other interactions. Source code: `generate_forecast_fxns.R`. ](../figures/forecast_uncertainty_example.pdf)

# A Brief History of Quantifying and Partitioning Forecast Uncertainty

##  Error propagation

Methods for quantifying and partitioning forecast uncertainty all share common roots in statistical error propagation.
Error propagation is concerned with translating the effects of variable (or parameter) uncertainty into the uncertainty of a function based those variables.
That is, for the output *q* of some function $q = f(x_1,x_2,\dots,x_n)$, we are interested in the variance of *q* given the variance of input variables (**x**).
It is this generic model formulation that leads to the canonical expression of error propagation

\begin{align}
\sigma^2_q &= \left( \frac{\delta q}{\delta x_1} \sigma_{x_1} \right)^2 + \left( \frac{\delta q}{\delta x_2} \sigma_{x_2} \right)^2 + \cdots + \left( \frac{\delta q}{\delta x_n} \sigma_{x_n} \right)^2 \\
&= \sum^n_{i=1}\left( \frac{\delta q}{\delta x_i} \sigma_{x_i} \right)^2.
\end{align}

This expression states that the variance of the output of function $q$ ($\sigma^2_q$) is equal to the sum of squares of the input variables weighted by the sensitivity of the output variable to each input variable, quantified as the partial derivative.

##  Weather forecasting

Chaos.

##  Earth system models

Carbon.

##  Dynamical models

Lotka-Volterra.

# A Simulation-Based Approach for Partitioning Forecast Uncertainty

Analytical expressions of forecast uncertainty must rely on simplifying assumptions.
Two important assumptions are (1) that different sources of uncertainty do not interact and (2) that the system of equations is linear.
These analytical expressions are important for guiding our intuition, but these strict assumptions limit our ability to partition forecast uncertainty in practice.
Thus, we present a simulation approach that is entirely model-based and requires no assumptions, other than those embedded in the model itself.
We are building on the ideas put forth by @Dietze2017a, who suggested a simulation approach for quantifying the terms in Eq. 2.
Here we test the general idea using simulated data and extend the approach to consider interactions among sources of uncertainty.

As a starting point, consider a generic Bayesian state-space model

\begin{align}
\textbf{Data Model:} \quad y_t &\sim \left[y_t \;|\; z_t, \sigma^2_{\text{o}}\right], &t = 1,\dots,T, \\
\textbf{Process Models:} \quad z_t &\sim \left[z_t \;|\; \mu_t, \sigma^2_{\text{p}}\right],  \\
\mu_t &= g \left(z_{t-1},\textbf{x}'_t, \bm{\uptheta} \right), &t = 2,\dots,T, \\
\textbf{Parameter Models:} \quad \bm{\upphi} &\sim \left[\bm{\uptheta},\sigma^2_{\text{p}},\sigma^2_{\text{o}},z_{t=1} \right],
\end{align}

\noindent{}where $y_t$ is the observed state at time *t*, $z_t$ is the latent state at time *t*, $\mu_t$ is the determinstic prediction of *z* at time *t* from the process model *g*, which is a function of *z* at time *t-1*, a vector of covariates (**x**) at time *t*, and a set of unknown parameters, $\bm{\uptheta}$.
$\sigma^2_{\text{o}}$ is observation error and $\sigma^2_{\text{p}}$ is process error.
The notation $\left[a \;|\; b, c\right]$ reads, "the probability of *a* given *b* and *c*" [@Gelfand1990], and $\bm{\upphi}$ refers to the prior probability distributions for all unknown parameters and the initial conditions for the latent state, $z_{t=1}$.

For our purposes, we are interested in the probability distributions of the true state **z** at future points in time, conditional on previous observations (**y**).
This is referred to as the forecast distribution or the predictive process distribution [@Hobbs2015, pp. 199-200], which, for one time step ahead of the final observation ($T+1$), is defined as

\begin{equation}
\begin{gathered}
\left[z_{T+1} | y_1,\dots,y_T \right] = \int \int \dots \int \left[z_{T+1} | z_T,\bm{\uptheta}, \sigma^2_{\text{p}} \right] \\ \times \left[z_1,\dots,z_T,\bm{\uptheta}, \sigma^2_{\text{p}} | y_1,\dots,y_T \right] d\bm{\uptheta} d\sigma^2_{\text{p}} dz_1 \dots dz_T.
\end{gathered}
\end{equation}

This type of model is easily fit using Bayesian methods and Markov chain Monte carlo (MCMC) algorithms.
The posterior distribution of all unkowns, including states and parameters, is estimated over *K* MCMC iterations.

![ Forecasts can be made using (A) a point estimate of the median of the latent state *z*, $\bar{z}_{(t)}$, as a starting value or (B) using the full distribution of *z*, $[z_{(t)}]$. In both panels, the small points are the estimates of *z* at time *t* from each of 1000 MCMC iterations, the boxplots show the distribution, and the large point shows the median. The scenario in A represents the case where initial conditions uncertainty is set to zero. Comparing the variance of forecasts made under scenarios A and B allows us to quantify the amount of uncertainty attributable to initial conditions. ](../figures/init_cond_example.pdf){ height=2in }

# Application: Yellowstone Bison Population


# References
