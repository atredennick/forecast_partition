---
title: A simulation-based approach for quantifying and partitioning uncertainty to improve forecasts of dynamic processes
author: Andrew T. Tredennick$^{1}$, Peter B. Adler$^1$, and others$^{2}$
csl: ecology.csl
output:
  pdf_document:
    keep_tex: yes
  html_document: default
geometry: left=1in, right=1in, top=1in, bottom=1in, headheight=12pt, letterpaper
header-includes:
- \usepackage[textsize=tiny,textwidth=2.1cm]{todonotes}
- \usepackage{mathptmx}
- \usepackage{upgreek}
- \usepackage{bm}
- \usepackage{setspace}
- \usepackage{booktabs}
- \doublespacing
- \usepackage{lineno}
- \linenumbers
- \usepackage{floatrow}
- \newcounter{box}
- \newcommand{\boxnumber}{\addtocounter{box}{1} \thebox \thinspace}
- \floatstyle{boxed}
- \newfloat{Box}{tbph}{box}
fontsize: 12pt
bibliography: /Users/atredenn/Dropbox/Bibliography/ecocast.bib
---

\newcommand{\smalltodo}[2][]
    {\todo[caption={#2}, #1]
    {\begin{spacing}{0.5}#2\end{spacing}}}
\setlength{\abovedisplayskip}{0pt}
\raggedright
\setlength{\parindent}{36pt}

$^1$ Department of Wildland Resources and the Ecology Center, Utah State University, Logan, UT, United States

$^2$ Department of somewhere

# Abstract

Making informed decisions in the face of rapid environmental change requires forecasts from models of ecological processes.
However, forecasts from ecological models are often associated with high degrees of uncertainty, making it difficult for such forecasts to inform decision-making processes.
To make progress toward the goal of reliable and informative ecological forecasts, we need to know from where forecast uncertainty arises.
Such knowledge can guide investment in future research that will most improve forecast skill.
There is a rich history of analytical expressions that partition the variance of future dynamics, but these expressions suffer from necessary assumptions such as linear dynamics and small-variance approximations that exclude interactions.
Similarly, the earth systems modeling community has developed methods for paritioning uncertainty of model projections, but these operate at a different modeling grain than most of ecology.
Building on these approaches, we develop a simulation-based approach for quantifying and partitioning forecast uncertainty from Bayesian state-space models that overcomes the limitations of previous analytical approaches.
Our approach is similar to an Analysis of Variance, where the total variance of a forecast is paritioned among its constituent parts, namely initial conditions uncertainty, parameter uncertainty, driver uncertainty, process error, and their interactions.
We apply the approach to near-term forecasts of the Yellowstone bison population and measles in China, demonstrating the broad utility of our approach.
We also provide functions written in the statistical programming language R, which will allow others using Bayesian state-space models to employ our approach in their own research.

*Keywords: Bayesian state-space model, forecast, Markov chain Monte Carlo, measles, prediction, population model, uncertainty, Yellowstone bison*

# Introduction

A fundamental challenge facing society is to predict the ecological impacts of global environmental changes such as nitrogen deposition, climate change, and habitat fragmentation.
Each of these global change drivers have now exceeded their historical ranges of variability [@Steffen2015], ushering in a no-analog era in which the past cannot predict the future.
We can, however, look to the past to parameterize models that allow us to forecast the future states of ecological systems [@Clark2001; @Dietze2018].
Ecologists are in an excellent position to meet this forecasting challenge because we have spent decades gaining understanding of the processes that regulate populations, communities, and ecosystems.
However, we lack a systematic understanding of the current limits to ecological forecasts.
As a result, we do not know how to allocate research effort to improve our forecasts.

Making poor forecasts is inevitable as ecology matures into a more predictive science.
The key is to learn from our failures so that forecasts become more accurate over time.
The success of meteorological forecasting tells us that basic research on the causes of forecast uncertainty is an essential component of this learning process [@Bauer2015].

Various approaches have been used to characterize and partition forecast uncertainty [@Sobol1993; @Cariboni2007].
For example, consider a dynamic model designed to predict some state *y* in the future ($y_{t+1}$) based on the current state ($y_{t}$), an environmental driver(s) ($x$), parameters ($\theta$), and process error ($\epsilon$).
We can then write a general form of the model as:

\begin{align}
y_{t+1} = f(y_t, x_t|\theta) + \epsilon_{t+1},
\end{align}

\noindent{}which states that $y$ at time $t+1$ is a function of $y$ and $x$ at time $t$ conditional on the model parameters ($\theta$) plus process error ($\epsilon$).
Ignoring covariance among factors and assuming linear dynamics, @Dietze2017a, following @Sobol1993 and @Cariboni2007, suggests that forecast variance ($Var[y_{t+1}]$) is approximately:

\begin{align}
Var[y_{t+1}] \approx \underbrace{\left(\frac{\delta f}{\delta y} \right)^2}_{\text{stability}} 
               \underbrace{\vphantom{ \left(\frac{\delta f}{\delta y} \right)^2 } Var[y_t]}_{\text{IC uncert.}} +
               \underbrace{\vphantom{ \left(\frac{\delta f}{\delta y} \right)^2 }\left(\frac{\delta f}{\delta x} \right)^2}_{\text{driver sens.}} 
               \underbrace{\vphantom{ \left(\frac{\delta f}{\delta y} \right)^2 } Var[x_t]}_{\text{driver uncert.}} +
               \underbrace{\vphantom{ \left(\frac{\delta f}{\delta y} \right)^2 }\left(\frac{\delta f}{\delta \theta} \right)^2}_{\text{param sens.}}
               \underbrace{\vphantom{ \left(\frac{\delta f}{\delta y} \right)^2 } Var[\theta]}_{\text{param. uncert.}} +
               \underbrace{\vphantom{ \left(\frac{\delta f}{\delta y} \right)^2 } Var[\epsilon_{t+1}]}_{\text{process error}},
\end{align}

\noindent{}where each additive term follows a pattern of *sensitivity* times *variance* and "IC uncert." refers to "*I*nitial *C*onditions uncertainty."
The variance attributable to any particular factor is a function of how sensitive the model is to the factor and the variance of that factor.
For example, the atmosphere is a chaotic system, meaning its dynamics are internally unstable and sensitive to initial conditions uncertainty.
This is why billions of dollars are spent each year to measure meterological variables -- meterologists learned that the key to reducing forecast error $(Var[y_{t+1}])$ was to reduce the uncertainty of initial conditions ($Var[y_t]$).
In contrast, ecologists are attempting to make actionable forecasts with little knowledge of which term in Eq. 2 dominates forecast error.
Knowing which term dominates forecast error in different ecological settings will advance our fundamental understanding of the natural world and immediately impact practical efforts to monitor, model, and predict ecological dynamics.

While having an analytical expression such as Eq. 2 is satisfying, arriving at the expression involves strict assumptions.
First, Eq. 2 only holds when the underlying dynamics are linear, which may not be the case for many populations and models.
Second, Eq. 2 only includes additive effects of each factor because the Taylor series decomposition requires small-variance approximations that eliminate interactions.
But, interactions among the factors are probably commone.
For example, in a simple simulation of an AR(1) process, we show that initial conditions uncertainty and parameter error interact to generate the full spread of forecast variance (Figure 1).
Therefore, progress in quantifying and partioning forecast uncertainty requires a more flexible approach than that provided by Eq. 2.

<!-- Rarely will only a single term in Eq. 2 determine forecast variance, and the importance of each term might shift over time [@Dietze2017a]. -->
<!-- For example, efforts to describe uncertainty in models of the global carbon cycle show that forecast variance from differences among carbon-emissions scenarios starts small but rises over time [@Lovenduski2017]. -->
<!-- Contrary to the analytical expression in Eq. 2, terms might also interact, rather than having additive effects. -->
<!-- A simple simulation experiment shows this clearly: initial conditions uncertainty and parameter uncertainty interact to produce the full spread of forecast error from an AR1 process model (Figure 1). -->
<!-- Simply relying on Eq. 2 could lead to a mischaracterization of the forces driving forecast uncertainty. -->
<!-- Therefore, progress requires a practical approach that can partition the main effects and interactions of each term in Eq. 2. -->

![ Example of forecast uncertainty with different sources of error set to zero. Each line represents one realization, out of 200, from an order-one autoregressive model (AR1 process). Contrary to the analytical expression (Eq. 2), initial conditions uncertainty and parameter uncertainty clearly interact. The spread of lines in (A) is not wholly because of initial conditions uncertainty (B) or parameter uncertainty (C), it is their combined influence that causes the spread of realizations in (A). At least in this example, process error (D) does appear to be independent, but we used a small value of process error to highlight other interactions. Source code: `generate_forecast_fxns.R`. ](../figures/forecast_uncertainty_example.pdf)

# A Brief History of Quantifying and Partitioning Forecast Uncertainty

##  Error propagation

Methods for quantifying and partitioning forecast uncertainty all share common roots in statistical error propagation.
Error propagation is concerned with translating the effects of variable (or parameter) uncertainty into the uncertainty of a function based those variables.
That is, for the output *q* of some function $q = f(x_1,x_2,\dots,x_n)$, we are interested in the variance of *q* given the variance of input variables (**x**).
It is this generic model formulation that leads to the canonical expression of error propagation

\begin{align}
\sigma^2_q &= \left( \frac{\delta q}{\delta x_1} \sigma_{x_1} \right)^2 + \left( \frac{\delta q}{\delta x_2} \sigma_{x_2} \right)^2 + \cdots + \left( \frac{\delta q}{\delta x_n} \sigma_{x_n} \right)^2 \\
&= \sum^n_{i=1}\left( \frac{\delta q}{\delta x_i} \sigma_{x_i} \right)^2.
\end{align}

\noindent{}This expression states that the variance of the output of function $q$ ($\sigma^2_q$) is equal to the sum of squares of the input variables weighted by the sensitivity of the output variable to each input variable, quantified as the partial derivative.

##  Weather forecasting

Chaos.

##  Earth system models

Carbon.

##  Dynamical models

Lotka-Volterra.

# A Simulation-Based Approach for Partitioning Forecast Uncertainty

Analytical expressions of forecast uncertainty must rely on simplifying assumptions.
Two important assumptions are (1) that different sources of uncertainty do not interact and (2) that the system of equations is linear.
These analytical expressions are important for guiding our intuition, but these strict assumptions limit our ability to partition forecast uncertainty in practice.
Thus, we present a simulation approach that is entirely model-based and requires no assumptions, other than those embedded in the model itself.
We are building on the ideas put forth by @Dietze2017a, who suggested a simulation approach for quantifying the terms in Eq. 2.
Here we test the general idea using simulated data and extend the approach to consider interactions among sources of uncertainty.

As a starting point, consider a generic Bayesian state-space model

\begin{equation}
\begin{aligned}[b]
\textbf{Data Model:} \quad y_t &\sim \left[y_t \;|\; z_t, \sigma^2_{\text{o}}\right], &t = 1,\dots,T, \\ 
\textbf{Process Models:} \quad z_t &\sim \left[z_t \;|\; \mu_t, \sigma^2_{\text{p}}\right],  \\ 
\mu_t &= g \left(z_{t-1},\textbf{x}'_t, \bm{\uptheta} \right), &t = 2,\dots,T, \\ 
\textbf{Parameter Models:} \quad \bm{\upphi} &\sim \left[\bm{\uptheta},\sigma^2_{\text{p}},\sigma^2_{\text{o}},z_{t=1} \right],
\end{aligned}
\end{equation}

\noindent{}where $y_t$ is the observed state at time *t*, $z_t$ is the latent state at time *t*, $\mu_t$ is the determinstic prediction of *z* at time *t* from the process model *g*, which is a function of *z* at time *t-1*, a vector of covariates (**x**) at time *t*, and a set of unknown parameters, $\bm{\uptheta}$.
$\sigma^2_{\text{o}}$ is observation error and $\sigma^2_{\text{p}}$ is process error.
The notation $\left[a \;|\; b, c\right]$ reads, "the probability of *a* given *b* and *c*" [@Gelfand1990], and $\bm{\upphi}$ refers to the prior probability distributions for all unknown parameters and the initial conditions for the latent state, $z_{t=1}$.

For our purposes, we are interested in the probability distributions of the true state **z** at future points in time, conditional on previous observations (**y**).
This is referred to as the forecast distribution or the predictive process distribution [@Hobbs2015, pp. 199-200], which, for one time step ahead of the final observation ($T+1$), is defined as

\begin{equation}
\begin{gathered}
\left[z_{T+1} | y_1,\dots,y_T \right] = \int \int \dots \int \left[z_{T+1} | z_T, \textbf{x}_T, \bm{\uptheta}, \sigma^2_{\text{p}} \right] \\ \times \left[z_1,\dots,z_{T+1},\bm{\uptheta}, \sigma^2_{\text{p}} | y_1,\dots,y_T \right] d\bm{\uptheta} d\sigma^2_{\text{p}} dz_1 \dots dz_T.
\end{gathered}
\end{equation}

The model in Eq. 5 can be fit using Markov chain Monte carlo (MCMC) algorithms, which makes calculating the forecast distribution a relatively simple task.
To obtain $\left[z_{T+1} | y_1,\dots,y_T \right]$, we can change the indexing of *t* in Eq. 3 to $t = 2,\dots,T+1$ and then sample $z_{T+1}^{(k)}$ from $\left[z_{T+1} | g(z_T^{(k)}, \textbf{x}_{T+1}^{(j(k))}, \bm{\uptheta}^{(k)}), \sigma^{2(k)}_{\text{p}} \right]$ given the current values for $\bm{\uptheta}^{(k)}$ and $z_{T}^{(k)}$ on each $k = 1,\dots,K$ iteration of the MCMC algorithm [@Hobbs2015; @Williams2018].
Note that we index the external covariate vector **x** using *j* and *k*, where *j(k)* is realization *j* of the covariate vector **x** associated with MCMC sample *k*.
In some cases, the external covariate will have only one value, in which case all *K* MCMC samples will share the same **x**.
In other cases, their may be a distribution of external covariate values associated with uncertainty from the forecast of **x**, resulting in *n* values for each $x_{T+1}$.
When $n < K$, which we anticipate it often will be, than **x** can be sampled with replacement and a value can be assigned to each MCMC sample. 
Making forecasts further into the future than $T+1$ requires extending $T+1$ to $T+2,\dots,T+q$ and iteratively sampling $\left[z_{T+q} | g(z_{T+q-1}^{(k)}, \textbf{x}_{T+q}^{(j(k))},\bm{\uptheta}^{(k)}), \sigma^{2(k)}_{\text{p}} \right]$ [@Hobbs2015].

The forecast distribution (Eq. 6) has all of the quantities that contribute to forecast uncertainty by incorporating their uncertainty explicitly across the *K* MCMC iterations.
For example, initial conditions uncertainty is incorporated because $z_{T+1}^{(k)}$ is a function of $z_{T}^{(k)}$, resulting in a total of *K* point forecasts for *z* that comprise the posterior distribution of *z* at each time *t*.
If we wish to ignore initial conditions uncertainty (I.C. uncertainty), we can make all *K* point forecasts starting from the mean of  $z_{T}$

\begin{equation}
z_{T}^{(*)} = E(z_{T} | y_1,\dots,y_T) \approx \frac{\sum^K_{k=1} z_{T}^{(k)}}{K},
\end{equation}

\noindent{}which we call $z^{(*)}_T$ (as opposed to $z^{(k)}_T$), while retaining the uncertainty around all other parameters.
Our iterative sampling to obtain the forecast distribution then becomes a conditional statement,

\begin{equation}
\begin{aligned}[b]
z_{T+q} &\sim \left[z_{T+q} | g(z_{T+q-1}^{(k)},\bm{\uptheta}^{(k)}), \sigma^{2(k)}_{\text{p}} \right], &q>1 \\
z_{T+q} &\sim \left[z_{T+q} | g(z_{T}^{(*)},\bm{\uptheta}^{(k)}), \sigma^{2(k)}_{\text{p}} \right], &q=1.
\end{aligned}
\end{equation}

We can extend the basic idea of setting subsets of parameters and states to their posterior means (or medians, depending on the distribution) to make partitioned forecasts where only prescribed sources of uncertainty contribute to forecast uncertainty,

\begin{equation}
\textbf{I.C. Uncertainty Only:} \quad z_{T+q} \sim \left[z_{T+q} | g(z_{T+q-1}^{(k)},\bm{\uptheta}^{(*)}), 0 \right]
\end{equation}
\begin{equation}
\begin{aligned}[b]
\textbf{Parameter Uncertainty Only:} \quad z_{T+q} &\sim \left[z_{T+q} | g(z_{T+q-1}^{(k)},\bm{\uptheta}^{(k)}), 0 \right], &q>1 \\
z_{T+q} &\sim \left[z_{T+q} | g(z_{T}^{(*)},\bm{\uptheta}^{(k)}), 0 \right], &q=1
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}[b]
\textbf{Process Uncertainty Only:} \quad z_{T+q} &\sim \left[z_{T+q} | g(z_{T+q-1}^{(k)},\bm{\uptheta}^{(*)}), \sigma^{2(k)}_{\text{p}} \right], &q>1 \\
z_{T+q} &\sim \left[z_{T+q} | g(z_{T}^{(*)},\bm{\uptheta}^{(*)}), \sigma^{2(k)}_{\text{p}} \right], &q=1,
\end{aligned}
\end{equation}

\noindent{}\smalltodo{Need to think about diff. between including process error ($E(\sigma^2_p)$) vs. process error uncertainty ($\sigma^{2(k)}_p$).}where $\sigma^{2}_{\text{p}} = 0$ in the case of no process uncertainty.
Eqs. 9-11 can be used in different combinations to examine the interactions of sources of uncertainty.

It is important to note that although our discussion has centered on obtaining forecast distributions within the MCMC algorithm used to fit the model, it is only feasible to do this for the full forecast distribution (Eq. 6).
In all other cases, where states or parameters must be averaged over the *K* MCMC iterations, forecast simulations must be done *post hoc* using saved MCMC samples (Box 1).
In other words, estimating $z_1,z_2,\dots,z_T$ is done within the MCMC fitting algorithm, while estimating $z_{T+1},z_{T+2},\dots,z_{T+q}$ is done after fitting the model, but with the full MCMC output.

With these basics in mind, we now develop our approach for partitioning and quantifying uncertainty, which is similar to an Analysis of Variance (ANOVA).
Let the variance of the forecast distribution at time $T+q$ be $V_{T+q}^{(X)}$, where $X=F$ (full forecast distribution), $I$ (initial conditions uncertainty only), $PA$ (parameter uncertainty only), or $PS$ (process uncertainty only).
$V_{T+q}^{(I)}$, $V_{T+q}^{(PA)}$, and $V_{T+q}^{(PS)}$ are the main effects of each factor on the forecast distribution such that

\begin{equation}
V_{T+q}^{(F)} = V_{T+q}^{(I)} + V_{T+q}^{(PA)} + V_{T+q}^{(PS)} + V_{T+q}^{(I,PA)} + V_{T+q}^{(I,PS)} + V_{T+q}^{(PA,PS)} + V_{T+q}^{(I,PA,PS)},
\end{equation}

\noindent{}where the notation $V_{T+q}^{(X,Y)}$ represents the remaining interactive effect of $X$ and $Y$ on the $V_{T+q}^{(F)}$ after accounting for their main effects.
Each of these terms can be attained by calculating the variance of the partitioned forecast distributions (Eqs. 9-11 and combinations thereof).

\begin{Box}
  \renewcommand{\arraystretch}{1.04}
  \caption{}
  \textbf{Box 1.} Pseudocode for quantifying and partitioning forecast uncertainty from a Bayesian state-space model. 
  \vspace{1em}
  \begin{enumerate}
    \item Fit a Bayesian state-space model (i.e., Eq. 5) with data $y_1,\dots,y_T$ and save the MCMC samples.
    \item Forecast $z_{T+q}^{(k)}$ for all $k = 1,\dots,K$ MCMC samples to generate the full forecast distribution following Eq. 6 (this can be done within the MCMC algorithm or \emph{post hoc} with saved MCMC samples).
    \item Forecast $z_{T+q}^{(k)}$ for all $k = 1,\dots,K$ MCMC samples to generate the partitioned forecast distributions for each source of uncertainty, averaging quantities over the $K$ MCMC samples as necessary (Eqs. 9-11 and combinations thereof).
    \item For each forecast time $q$, calculate the variance of each forecast distribution from steps 2-3.
    \item Partition forecast variance using Eq. X.
  \end{enumerate}
  \renewcommand{\arraystretch}{1.0}
\end{Box}



<!-- ![ Forecasts can be made using (A) a point estimate of the median of the latent state *z*, $\bar{z}_{(t)}$, as a starting value or (B) using the full distribution of *z*, $[z_{(t)}]$. In both panels, the small points are the estimates of *z* at time *t* from each of 1000 MCMC iterations, the boxplots show the distribution, and the large point shows the median. The scenario in A represents the case where initial conditions uncertainty is set to zero. Comparing the variance of forecasts made under scenarios A and B allows us to quantify the amount of uncertainty attributable to initial conditions. ](../figures/init_cond_example.pdf){ height=2in } -->

# Application: Yellowstone Bison Population

# Application: Measles in China

# Acknowledgements
This research was funded by National Science Foundation grants DEB-1353078 (awarded to PBA) and DEB-1353039 (awarded to Stephen P. Ellner and Giles Hooker).

\setlength{\parindent}{0pt}
# References
